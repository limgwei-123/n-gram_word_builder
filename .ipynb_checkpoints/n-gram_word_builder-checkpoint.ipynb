{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cf042587-cda3-4528-8ab3-64ad685eff2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus = \"\"\"\n",
    "我今天去学校上课。\n",
    "我今天去吃饭。\n",
    "你今天去哪里？\n",
    "我不想去上课。\n",
    "你不想去学校吗？\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9dfe8760-bbe4-4382-a386-8bc0c73b6316",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import re\n",
    "\n",
    "def tokenize_text_to_sentences(text: str):\n",
    "    sents = re.split(r\"[。？！\\n]\", text)\n",
    "    sents = [s.strip() for s in sents if s.strip()]\n",
    "    return sents\n",
    "\n",
    "def tokenize_sentence_char_level(sent: str):\n",
    "    sent = re.sub(r\"\\s+\", \"\", sent)\n",
    "    return list(sent)\n",
    "\n",
    "def add_sentence_tokens(tokens, n):\n",
    "    return [\"<s>\"] * (n - 1) + tokens + [\"</s>\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "18618caa-7fad-489f-9e66-7dce46005e38",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['我今天去学校上课', '我今天去吃饭', '你今天去哪里', '我不想去上课', '你不想去学校吗']\n",
      "我今天去学校上课 -> ['我', '今', '天', '去', '学', '校', '上', '课']\n",
      "我今天去吃饭 -> ['我', '今', '天', '去', '吃', '饭']\n",
      "你今天去哪里 -> ['你', '今', '天', '去', '哪', '里']\n",
      "我不想去上课 -> ['我', '不', '想', '去', '上', '课']\n",
      "你不想去学校吗 -> ['你', '不', '想', '去', '学', '校', '吗']\n"
     ]
    }
   ],
   "source": [
    "sents = tokenize_text_to_sentences(corpus)\n",
    "print(sents)\n",
    "for s in sents:\n",
    "    print(s, \"->\", tokenize_sentence_char_level(s))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "4652df89-ed4b-4d50-8c24-1c54f719e91a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "\n",
    "def build_ngram_counts(sentences, n:int):\n",
    "    context_counts = defaultdict(int)\n",
    "    next_counts = defaultdict(int)\n",
    "\n",
    "    for sent in sentences:\n",
    "        tokens = tokenize_sentence_char_level(sent)\n",
    "        tokens = add_sentence_tokens(tokens, n)\n",
    "        \n",
    "        for i in range (n - 1, len(tokens)):\n",
    "            context = tuple(tokens[i - (n-1):i])\n",
    "            nxt = tokens[i]\n",
    "            context_counts[context] += 1\n",
    "            next_counts[(context, nxt)] += 1\n",
    "\n",
    "    return context_counts, next_counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "c9569bba-1961-4aae-ac93-e45e6e90e602",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "context example: [(('<s>', '<s>'), 5), (('<s>', '我'), 3), (('我', '今'), 2), (('今', '天'), 3), (('天', '去'), 3)]\n",
      "next example: [((('<s>', '<s>'), '我'), 3), ((('<s>', '我'), '今'), 2), ((('我', '今'), '天'), 2), ((('今', '天'), '去'), 3), ((('天', '去'), '学'), 1)]\n"
     ]
    }
   ],
   "source": [
    "n = 3  # trigram\n",
    "context_counts, next_counts = build_ngram_counts(sents, n)\n",
    "\n",
    "print(\"context example:\", list(context_counts.items())[:5])\n",
    "print(\"next example:\", list(next_counts.items())[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "38c62d49-e827-49e7-a0c3-18da8950f19b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "def sample_next_token(context, next_counts):\n",
    "    candidates = []\n",
    "    weights = []\n",
    "\n",
    "    for (ctx, nxt), c in next_counts.items():\n",
    "        if ctx == context:\n",
    "            candidates.append(nxt)\n",
    "            weights.append(c)\n",
    "\n",
    "    if not candidates:\n",
    "        return None\n",
    "\n",
    "    return random.choices(candidates, weights = weights, k=1)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "60ec8e6b-424d-4341-b5d0-2363da0db717",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_text(n, next_counts, max_len = 50):\n",
    "    context = tuple([\"<s>\"] * (n - 1))\n",
    "    output = []\n",
    "\n",
    "    for _ in range(max_len):\n",
    "        nxt = sample_next_token(context, next_counts)\n",
    "        if nxt is None:\n",
    "            break\n",
    "        if nxt == \"</s>\":\n",
    "            break\n",
    "\n",
    "        output.append(nxt)\n",
    "        context = tuple(list(context[1:]) + [nxt])\n",
    "\n",
    "    return \"\".join(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "c81f0f9e-4aa8-4bfd-980e-c82be245d1e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "你今天去学校上课\n",
      "我今天去哪里\n",
      "你今天去哪里\n",
      "我今天去吃饭\n",
      "我不想去学校上课\n",
      "我今天去哪里\n",
      "你不想去上课\n",
      "我不想去学校上课\n",
      "我今天去吃饭\n",
      "我今天去哪里\n"
     ]
    }
   ],
   "source": [
    "for _ in range(10):\n",
    "    print(generate_text(n, context_counts, next_counts))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9af3176-2a54-459f-8612-bcba4d538881",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
